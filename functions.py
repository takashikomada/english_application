import streamlit as st
import os
import time
from pathlib import Path
import wave
import pyaudio
from pydub import AudioSegment
from audiorecorder import audiorecorder
import numpy as np
from scipy.io.wavfile import write
from langchain.prompts import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    MessagesPlaceholder,
)
from langchain.schema import SystemMessage, HumanMessage
from langchain.memory import ConversationSummaryBufferMemory
from langchain_openai import ChatOpenAI
from langchain.chains import ConversationChain
import constants as ct


def record_audio(audio_input_file_path):
    """
    éŸ³å£°å…¥åŠ›ã‚’å—ã‘å–ã£ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    """

    audio = audiorecorder(
        start_prompt="ç™ºè©±é–‹å§‹",
        pause_prompt="ã‚„ã‚Šç›´ã™",
        stop_prompt="ç™ºè©±çµ‚äº†",
        start_style={"color": "white", "background-color": "black"},
        pause_style={"color": "gray", "background-color": "white"},
        stop_style={"color": "white", "background-color": "black"},
    )

    if len(audio) > 0:
        audio.export(audio_input_file_path, format="wav")
    else:
        st.stop()


def transcribe_audio(audio_input_file_path):
    """
    éŸ³å£°å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
    Args:
        audio_input_file_path: éŸ³å£°å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    """

    with open(audio_input_file_path, "rb") as audio_input_file:
        transcript = st.session_state.openai_obj.audio.transcriptions.create(
            model="whisper-1",
            file=audio_input_file,
            language="en",
        )

    # éŸ³å£°å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    os.remove(audio_input_file_path)

    return transcript


def save_to_wav(llm_response_audio, audio_output_file_path):
    """
    ä¸€æ—¦mp3å½¢å¼ã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå¾Œã€wavå½¢å¼ã«å¤‰æ›
    Args:
        llm_response_audio: LLMã‹ã‚‰ã®å›ç­”ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿
        audio_output_file_path: å‡ºåŠ›å…ˆã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    """

    temp_audio_output_filename = (
        f"{ct.AUDIO_OUTPUT_DIR}/temp_audio_output_{int(time.time())}.mp3"
    )
    with open(temp_audio_output_filename, "wb") as temp_audio_output_file:
        temp_audio_output_file.write(llm_response_audio)

    audio_mp3 = AudioSegment.from_file(temp_audio_output_filename, format="mp3")
    audio_mp3.export(audio_output_file_path, format="wav")

    # éŸ³å£°å‡ºåŠ›ç”¨ã«ä¸€æ™‚çš„ã«ä½œã£ãŸmp3ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    os.remove(temp_audio_output_filename)


def play_wav(audio_output_file_path, speed=1.0):
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿ä¸Šã’
    Args:
        audio_output_file_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        speed: å†ç”Ÿé€Ÿåº¦ï¼ˆ1.0ãŒé€šå¸¸é€Ÿåº¦ã€0.5ã§åŠåˆ†ã®é€Ÿã•ã€2.0ã§å€é€Ÿãªã©ï¼‰
    """

    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    audio = AudioSegment.from_wav(audio_output_file_path)

    # é€Ÿåº¦ã‚’å¤‰æ›´ï¼ˆpydub ã§æ³¢å½¢ã‚’å¤‰å½¢ï¼‰
    if speed != 1.0:
        modified_audio = audio._spawn(
            audio.raw_data,
            overrides={"frame_rate": int(audio.frame_rate * speed)},
        )
        # å…ƒã® frame_rate ã«æˆ»ã—ã¦ãƒ”ãƒƒãƒã‚’ç¶­æŒ
        modified_audio = modified_audio.set_frame_rate(audio.frame_rate)
        modified_audio.export(audio_output_file_path, format="wav")

    # ãƒ–ãƒ©ã‚¦ã‚¶å´ã§å†ç”Ÿã™ã‚‹ãŸã‚ã«ãƒã‚¤ãƒˆåˆ—ã«å¤‰æ›
    with open(audio_output_file_path, "rb") as f:
        audio_bytes = f.read()

    # ğŸ”¸ ãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜ï¼ˆrerun å¯¾ç­–ï¼‰
    st.session_state["dictation_audio_bytes"] = audio_bytes

    # ã“ã®å®Ÿè¡Œã§ã‚‚ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’è¡¨ç¤º
    st.audio(audio_bytes, format="audio/wav")

    # â€» Cloud ã§ã¯ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã¯ã›ãšã€ã‚µãƒ¼ãƒå´ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã«ä»»ã›ã‚‹
    # os.remove(audio_output_file_path)


def create_chain(system_template):
    """
    LLMã«ã‚ˆã‚‹å›ç­”ç”Ÿæˆç”¨ã®Chainä½œæˆ
    """

    prompt = ChatPromptTemplate.from_messages(
        [
            SystemMessage(content=system_template),
            MessagesPlaceholder(variable_name="history"),
            HumanMessagePromptTemplate.from_template("{input}"),
        ]
    )
    chain = ConversationChain(
        llm=st.session_state.llm,
        memory=st.session_state.memory,
        prompt=prompt,
    )

    return chain


def create_problem_and_play_audio():
    """
    å•é¡Œç”Ÿæˆã¨éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å†ç”Ÿ
    """

    # å•é¡Œæ–‡ã‚’ç”Ÿæˆã™ã‚‹Chainã‚’å®Ÿè¡Œã—ã€å•é¡Œæ–‡ã‚’å–å¾—
    problem = st.session_state.chain_create_problem.predict(input="")

    # LLMã‹ã‚‰ã®å›ç­”ã‚’éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
    llm_response_audio = st.session_state.openai_obj.audio.speech.create(
        model="tts-1",
        voice="alloy",
        input=problem,
    )

    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
    audio_output_file_path = (
        f"{ct.AUDIO_OUTPUT_DIR}/audio_output_{int(time.time())}.wav"
    )
    save_to_wav(llm_response_audio.content, audio_output_file_path)

    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿ä¸Šã’
    play_wav(audio_output_file_path, st.session_state.speed)

    return problem, llm_response_audio


def create_evaluation(system_template: str) -> str:
    """
    è©•ä¾¡å°‚ç”¨LLMã‚’ä½¿ã£ã¦ã€å•é¡Œæ–‡ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ç­”ã‚’è©•ä¾¡ã™ã‚‹
    Args:
        system_template: constants.SYSTEM_TEMPLATE_EVALUATION ã‚’ format ã—ãŸæ–‡å­—åˆ—
    """

    messages = [
        SystemMessage(content=system_template),
        HumanMessage(
            content="ä¸Šè¨˜ã®æ¡ä»¶ã«ã—ãŸãŒã£ã¦ã€å•é¡Œæ–‡ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ç­”ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚"
        ),
    ]

    response = st.session_state.eval_llm.invoke(messages)
    return response.content
